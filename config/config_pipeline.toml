[pipeline]
display=1
is_aarch64=1
known_face_dir="data/known_faces"
save_feature_path="data/features"
save_feature=0
realtime=0

[streammux]
gpu_id=0
batch-size=8                    # = number of sources (if all active simultaneously)
width=640                       # match YOLOv8n input size
height=640                      # match YOLOv8n input size
batched-push-timeout=30000      # in Âµs (40ms = 25 FPS target). Adjust depending on FPS of sources.
#enable-padding=1               # keep aspect ratio, pad with black
#nvbuf-memory-type=0            # default (0: system, 2: device). On NX keep 0 for stability
#live-source=1                  # important for RTSP
sync-inputs=0                   # Do not wait for slow sources; push batch as inputs arrive

[nvosd]
process-mode=0
display-text=1

[source]
"5e1999edcc8e410fb4b0d1011e6b15de" = "rtsp://admin:123456Aa@192.168.0.213:1554/Streaming/Channels/601"
"625d66f10a0b4a0a920be73f705773bd" = "rtsp://admin:wesmart!@192.168.0.243:554/Unicast/channels/101"
"c9bb715db20a489f94f58d36bb3602d0" = "rtsp://admin:123456Aa@192.168.0.213:1554/Streaming/Channels/301"
"d73cf20e2aa544b7b352070f24bff721" = "rtsp://admin:123456Aa@192.168.0.213:1554/Streaming/Channels/401"

[pgie]
#config-file-path="config/config_retinaface.txt"
config-file-path="config/config_yolov8n_face.txt"

[sgie]
config-file-path="config/config_arcface.txt"

[tracker]
config-file-path="config/config_tracker_perf.txt"

[tiler]
width=1920
height=1080
#enable-padding=1

[sink]
qos=1
sync=0

[recognition]
# Cosine similarity (higher = stricter)
threshold=0.5
# Directory to save recognized face images
save_dir="data/faces/recognized"
# Save mode for recognized images: "all" (every frame), "first" (first per track), "best" (best score per track)
save_mode="first"
# Backend: "faiss" (default), "cuvs" (experimental; requires RAPIDS cuVS), or "auto"
backend="faiss"
# If your known_face_dir has images instead of .npy embeddings, you can point to a folder of .npy features
# to build the index from. If empty or not set, will use known_face_dir.
feature_dir="data/known_faces"
# Vector index configuration
# Use FAISS-based index for matching (1 to enable, 0 to disable)
use_index=1
# Metric for matching: "cosine" (inner product) or "l2"
metric="cosine"
# FAISS index type: "flat" (exact), "ivf" (coarse quantizer), or "ivfpq" (compressed)
index_type="flat"
# GPU acceleration (requires faiss-gpu); falls back to CPU if unavailable
use_gpu=0
gpu_id=0
# IVF lists (only for ivf/ivfpq); if 0, auto sqrt(N)
nlist=0
# PQ sub-vectors (only for ivfpq); if 0, auto dim/8
m_pq=0
nbits_pq=8
# Persisted index paths (optional); if present, will attempt to load; else build and save
index_path="data/index/faiss.index"
labels_path="data/index/labels.json"

# --- Live indexing options ---
# Enable adding embeddings from the live stream into the index
index_stream=0
# Indexing mode: "per_track" | "per_frame"
index_mode="per_track"
# "track" | "name"
index_label="name"
# Optional: live-updated index; if empty, reuse index_path/labels_path
stream_index_path="data/index/live.index"
stream_labels_path="data/index/live_labels.json"

# Recognize once per track: 1 enable, 0 disable
recognize_once_per_track=1

[debug]
# Verbose console prints (matching per-frame)
verbose=1

[thresholds]
# Minimum PGIE detection confidence to keep faces (env PGIE_MIN_CONF overrides if set)
pgie_min_conf=0.5

[events]
# Enable sending recognition events over Unix domain socket
enable=1
# Path to Unix domain socket listened by the receiver process
unix_socket="/tmp/my_socket"
# Include image bytes in the packet (PNG/JPEG). 1=yes, 0=no
send_image=1

[mqtt]
# Local MQTT broker settings (core_v2 style)
host = "localhost"
port = 1883
# Topics
request_topic = "/local/core/v2/ai/request"
response_topic = "/local/core/v2/ai/response"
