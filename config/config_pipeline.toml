[pipeline]
display=0
is_aarch64=1
known_face_dir="data/known_faces"
save_feature_path="data/features"
save_feature=0
realtime=1

[streammux]
gpu_id=0
batch-size=4
width=1920
height=1080
batched-push-timeout=1000
# Do not wait for slow sources; push batch as inputs arrive
sync-inputs=0

[nvosd]
process-mode=0
display-text=1

[source]
"f5c4a7a1-1b2c-4d3e-8f90-111111111111" = "file:///home/m2n/edge-deepstream/data/media/friends_s1e1_cut.mp4"
"a2b3c4d5-6e7f-8901-2345-222222222222" = "rtsp://admin:wesmart!@192.168.0.243:554/Streaming/Channels/101"
"b3c4d5e6-f701-2345-6789-333333333333" = "rtsp://admin:123456Aa@192.168.0.213:1554/Streaming/Channels/301"
"c4d5e6f7-0123-4567-89ab-444444444444" = "rtsp://admin:123456Aa@192.168.0.213:1554/Streaming/Channels/401"

[pgie]
#config-file-path="config/config_retinaface.txt"
config-file-path="config/config_yolov8n_face.txt"

[sgie]
config-file-path="config/config_arcface.txt"

[tracker]
config-file-path="config/config_tracker_perf.txt"

[tiler]
width=1920
height=1080

[sink]
qos=1
sync=0

[recognition]
# Cosine similarity threshold for accepting a match (higher = stricter)
threshold=0.5
# Directory to save recognized face images
save_dir="data/faces/recognized"
# Save mode for recognized images: "all" (every frame), "first" (first per track), "best" (best score per track)
save_mode="first"
# Backend: "faiss" (default), "cuvs" (experimental; requires RAPIDS cuVS), or "auto"
backend="faiss"
# If your known_face_dir has images instead of .npy embeddings, you can point to a folder of .npy features
# to build the index from. If empty or not set, will use known_face_dir.
feature_dir="data/known_faces"
# Vector index configuration
# Use FAISS-based index for matching (1 to enable, 0 to disable)
use_index=1
# Metric for matching: "cosine" (inner product) or "l2"
metric="cosine"
# FAISS index type: "flat" (exact), "ivf" (coarse quantizer), or "ivfpq" (compressed)
index_type="flat"
# GPU acceleration (requires faiss-gpu); falls back to CPU if unavailable
use_gpu=0
gpu_id=0
# IVF lists (only for ivf/ivfpq); if 0, auto sqrt(N)
nlist=0
# PQ sub-vectors (only for ivfpq); if 0, auto dim/8
m_pq=0
nbits_pq=8
# Persisted index paths (optional); if present, will attempt to load; else build and save
index_path="data/index/faiss.index"
labels_path="data/index/labels.json"

# --- Live indexing options ---
# Enable adding embeddings from the live stream into the index
index_stream=0
# Indexing mode: "per_track" (add once per NVTracker track id) or "per_frame" (add every frame)
index_mode="per_track"
# Labeling for indexed entries: "track" (label as track-<id>) or "name" (use recognized name when available)
index_label="name"
# Optional alternate paths to save the live-updated index; if empty, reuse index_path/labels_path
stream_index_path="data/index/live.index"
stream_labels_path="data/index/live_labels.json"

# Recognize once per track to reduce per-frame matching cost (1 enable, 0 disable)
recognize_once_per_track=1

[debug]
# Verbose console prints (matching per-frame)
verbose=1

[thresholds]
# Minimum PGIE detection confidence to keep faces (env PGIE_MIN_CONF overrides if set)
pgie_min_conf=0.6

[events]
# Enable sending recognition events over Unix domain socket
enable=1
# Path to Unix domain socket listened by the receiver process
unix_socket="/tmp/my_socket"
# Include image bytes in the packet (PNG/JPEG). 1=yes, 0=no
send_image=1

[mqtt]
# Local MQTT broker settings (core_v2 style)
host = "localhost"
port = 1883
# Topics
request_topic = "/local/core/v2/ai/request"
