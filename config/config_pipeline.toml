[pipeline]
display=1
is_aarch64=1
known_face_dir="data/known_faces"
save_feature_path="data/features"
save_feature=0
realtime=1

[streammux]
gpu_id=0
batch-size=8
width=1920
height=1080
batched-push-timeout=200
# Do not wait for slow sources; push batch as inputs arrive
sync-inputs=0

[nvosd]
process-mode=0
display-text=1

[source]
"1" = "rtsp://admin:wesmart!@192.168.0.243:554/Streaming/Channels/101"

[pgie]
#config-file-path="config/config_retinaface.txt"
config-file-path="config/config_yolov8n_face.txt"

[sgie]
config-file-path="config/config_arcface.txt"

[tracker]
config-file-path="config/config_tracker_perf.txt"

[tiler]
width=1920
height=1080
rows=4
columns=2

[sink]
qos=1
sync=0

[recognition]
# Cosine similarity (higher = stricter)
threshold=0.5
# Directory to save recognized face images
save_dir="data/faces/recognized"
# Save mode for recognized images: "all" (every frame), "first" (first per track), "best" (best score per track)
save_mode="first"
# Backend: "faiss" (default), "cuvs" (experimental; requires RAPIDS cuVS), or "auto"
backend="faiss"
# If your known_face_dir has images instead of .npy embeddings, you can point to a folder of .npy features
# to build the index from. If empty or not set, will use known_face_dir.
feature_dir="data/known_faces"
# Vector index configuration
# Use FAISS-based index for matching (1 to enable, 0 to disable)
use_index=1
# Metric for matching: "cosine" (inner product) or "l2"
metric="cosine"
# FAISS index type: "flat" (exact), "ivf" (coarse quantizer), or "ivfpq" (compressed)
index_type="flat"
# GPU acceleration (requires faiss-gpu); falls back to CPU if unavailable
use_gpu=0
gpu_id=0
# IVF lists (only for ivf/ivfpq); if 0, auto sqrt(N)
nlist=0
# PQ sub-vectors (only for ivfpq); if 0, auto dim/8
m_pq=0
nbits_pq=8
# Persisted index paths (optional); if present, will attempt to load; else build and save
index_path="data/index/faiss.index"
labels_path="data/index/labels.json"

# --- Live indexing options ---
# Enable adding embeddings from the live stream into the index
index_stream=0
# Indexing mode: "per_track" | "per_frame"
index_mode="per_track"
# "track" | "name"
index_label="name"
# Optional: live-updated index; if empty, reuse index_path/labels_path
stream_index_path="data/index/live.index"
stream_labels_path="data/index/live_labels.json"

# Recognize once per track: 1 enable, 0 disable
recognize_once_per_track=1

[debug]
# Verbose console prints (matching per-frame)
verbose=0

[thresholds]
# Minimum PGIE detection confidence to keep faces (env PGIE_MIN_CONF overrides if set)
pgie_min_conf=0.6

[events]
# Enable sending recognition events over Unix domain socket
enable=0
# Path to Unix domain socket listened by the receiver process
unix_socket="/tmp/my_socket"
# Include image bytes in the packet (PNG/JPEG). 1=yes, 0=no
send_image=1

[mqtt]
# Local MQTT broker settings (core_v2 style)
host = "localhost"
port = 1883
# Topics
request_topic = "/local/core/v2/ai/request"
response_topic = "/local/core/v2/ai/response"